---
title: "Assignment 4 - Coordinating Heart Rate"
author: "Lasse Damgaard"
date: "December 12, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Analysing Heart Rate and Respiration data

The goal of this assignment is to first familiarize you with heart rate, and respiration data and their preprocessing. The second part explores how to analyze interpersonal coordination of these signals.

These are the questions you need to be able to answer at the end of the assignment (aka that you need to submit as part of the portfolio)

1) How do you preprocess heart rate and respiration data? Describe the process. If any data needs to be excluded, list the excluded data and motivate the exclusion.

 
```{r}

setwd("C:/Users/Bruger/Documents/Methods3")

library(pacman)
p_load(dplyr, groupdata2, ggplot2, stringr, crqa, plyr, gridExtra, lmerTest)

folder = "C:/Users/Bruger/Documents/Methods3/CleanData/"
fileList = list.files(path=folder, pattern="*.csv")

part1 = read.csv(paste(folder, fileList[1], sep = ""))


#Scaling
part1$temp = 1 
rescalelist = c("Resp1", "Resp2", "ECG1", "ECG2", "HR1", "HR2") 

part1_rescaled = part1[, colnames(part1) %in% rescalelist] %>% 
  lapply(. , function(x) scale(x, center = mean(x, na.rm =T), scale = sd(x, na.rm = T))) %>% 
  cbind(. , part1[,! colnames(part1) %in% rescalelist]) 

#Downsampling
part1_rescaled = part1_rescaled %>% group(n= 100, method= 'greedy') %>% 
  summarise_all(.,funs(mean(., na.rm = TRUE))) 

part1_rescaled = subset(part1_rescaled, select=-c(temp, .groups)) 

#Removing outliers
removeOuts = function(ts, threshold){
  ts[ts > (mean(ts,na.rm=T) + (threshold*sd(ts,na.rm=T))) | 
       ts < (mean(ts,na.rm=T) - (threshold*sd(ts,na.rm=T)))] = mean(ts,na.rm=T)
return(ts)
}

part1_rescaled$Resp2.1 = removeOuts(part1_rescaled$Resp2, 1.5)
part1_rescaled$HR2.1 = removeOuts(part1_rescaled$HR2, 1.5)

plot1 = ggplot2::ggplot(part1_rescaled, aes(x = time, y = Resp2)) + 
  geom_line(color = "red") +   geom_line(aes(x = time, y = HR2), color = "green")
plot2 = ggplot2::ggplot(part1_rescaled, aes(x = time, y = Resp2.1)) + 
  geom_line(color = "red") +   geom_line(aes(x = time, y = HR2.1), color = "green")
plot3 = ggplot2::ggplot(part1_rescaled, aes(x = time, y = Resp1)) + 
  geom_line(color = "red") +   geom_line(aes(x = time, y = HR1), color = "green")

#Scale function 
KCE_scale = function(df, rescalelist = NULL){
  if (is.null(rescalelist) == T){ #if rescalelist is not specified rescale all the variables
    rescalelist = colnames(df)
  }
  df$temp = 1 #to make the rescale work all the time (cbind does not work if there isn't )
  df$temp1 = 1
  scaled_df = df[, colnames(df) %in% rescalelist] %>% #select rows to rescale 
    lapply(. , function(x) scale(x, center = mean(x, na.rm =T), scale = sd(x, na.rm = T))) %>% 
    cbind(. , df[,! colnames(df) %in% rescalelist]) #bind with remaining rows
  scaled_df = subset(scaled_df, select=-c(temp, temp1))
  return(scaled_df)
}

#Downsample function
downsample = function(df){
  downsampled_df = df %>% group(n= 100, method= 'greedy') %>% 
    summarise_all(funs(mean(., na.rm = TRUE))) 
    downsampled_df = subset(downsampled_df, select=-c(.groups))
  return(downsampled_df)
}

# Kenneth's remove outlier function 
KCE_removeOuts = function(df, threshold, rm_list = NULL){
  if (is.null(rm_list) == T){ #if rm_list is not specified rescale all the variables
    rm_list = colnames(df)
  }
  df$temp = 1 #to make the rescale work all the time (cbind does not work if there isn't )
  df$temp1 = 1
  noOutlier_df = df[, colnames(df) %in% rm_list] %>% #select rows to remove outliers from 
    lapply(. , function(x) removeOuts(ts = x, threshold = threshold)) %>% 
    cbind(. , df[,! colnames(df) %in% rm_list])
  noOutlier_df = subset(noOutlier_df, select=-c(temp, temp1))
  return(noOutlier_df)
}

for (file in fileList){
  temp = read.csv(paste(folder, file, sep = ""))
  n = match(file, fileList)
  
  temp = dplyr::select(temp, Resp1, Resp2, HR1, HR2, time)
  
  # Scaling, downsampling and removing outliers
  temp = KCE_removeOuts(temp, threshold = 1.5, rm_list = c("Resp1", "Resp2", "ECG1", "ECG2", "HR1", "HR2"))
  temp = downsample(temp)
  temp = KCE_scale(temp, rescalelist = c("Resp1", "Resp2", "ECG1", "ECG2", "HR1", "HR2"))

  # Extracting features from filename
  temp$group = str_extract(str_extract(file, "G\\d+"), "\\d+")
  temp$trial = str_extract(str_extract(file, "T\\d"), "\\d")
  temp$studynr = str_extract(str_extract(file, "Study\\d+"), "\\d+")
  temp$condition = gsub("Study_G_T_","", gsub("\\d","", gsub(".csv", "", file)))
  temp$n = n

  # Saving result
  if (n == 1){ 
  all_dat = temp
  } else { 
    all_dat = rbind(all_dat, temp)
  }
  
  # Making plots 
  plot_p1 = ggplot2::ggplot(temp, aes(x = time, y = Resp1)) + 
    geom_line(color = "red") +   geom_line(aes(x = time, y = HR1), color = "green")
  plot_p2 = ggplot2::ggplot(temp, aes(x = time, y = Resp2)) + 
    geom_line(color = "red") +   geom_line(aes(x = time, y = HR2), color = "green")

    # Saving plot
  assign(paste("plot", n + 0.1, sep = ""), plot_p1) 
  assign(paste("plot", n + 0.2, sep = ""), plot_p2)
}

# Plotting to check for artifacts
gridExtra::grid.arrange(plot1.1, plot1.2) 
gridExtra::grid.arrange(plot2.1, plot2.2) 
gridExtra::grid.arrange(plot3.1, plot3.2) 
gridExtra::grid.arrange(plot4.1, plot4.2) 
gridExtra::grid.arrange(plot5.1, plot5.2) 
gridExtra::grid.arrange(plot6.1, plot6.2) 
gridExtra::grid.arrange(plot7.1, plot7.2) 
gridExtra::grid.arrange(plot8.1, plot8.2) 
gridExtra::grid.arrange(plot9.1, plot9.2) 
gridExtra::grid.arrange(plot10.1, plot10.2) 
gridExtra::grid.arrange(plot11.1, plot11.2)
gridExtra::grid.arrange(plot12.1, plot12.2) 
gridExtra::grid.arrange(plot13.1, plot13.2)
gridExtra::grid.arrange(plot14.1, plot14.2)
gridExtra::grid.arrange(plot15.1, plot15.2) 
gridExtra::grid.arrange(plot16.1, plot16.2)
gridExtra::grid.arrange(plot17.1, plot17.2) 
gridExtra::grid.arrange(plot18.1, plot18.2) 
gridExtra::grid.arrange(plot19.1, plot19.2)
gridExtra::grid.arrange(plot20.1, plot20.2)
gridExtra::grid.arrange(plot21.1, plot21.2) 
gridExtra::grid.arrange(plot22.1, plot22.2)
gridExtra::grid.arrange(plot23.1, plot23.2)
gridExtra::grid.arrange(plot24.1, plot24.2)
gridExtra::grid.arrange(plot25.1, plot25.2)
gridExtra::grid.arrange(plot26.1, plot26.2)
gridExtra::grid.arrange(plot27.1, plot27.2)
gridExtra::grid.arrange(plot28.1, plot28.2) 
gridExtra::grid.arrange(plot29.1, plot29.2)
gridExtra::grid.arrange(plot30.1, plot30.2)

# Removing bad data
all_dat = subset(all_dat, !(n %in% c(1, 2, 4, 5)))
removedFiles = c(fileList[1:2], fileList[4:5])

# Defining a function to extract optimal parameters
opt_par_extractor = function(dataset, t1, t2, n = NA){ 
  par = list(lgM =  50, steps = seq(1, 6, 1),  radiusspan = 100,  radiussample = 40, normalize = 0,  rescale = 0,  mindiagline = 2,  minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE,  fnnpercent = 10,  typeami = "mindip")
  opt_param = NULL
  t1 = dplyr::select(dataset, t1)
  t2 = dplyr::select(dataset, t2)
  opt_param = try(optimizeParam(t1, t2, par, min.rec = 3, max.rec = 4))
  if (length(opt_param) > 1) {
    result_df = data.frame(opt_param[1], opt_param[2], opt_param[3], n = n) 
    } else {
    result_df = data.frame(radius = NA, emddim = NA, delay = NA, n = n)
    }
  return(result_df)
}

# Extracting optimal parameters from the data
for (i in 1:length(unique(all_dat$n))){
  subset_dat = subset(all_dat, n == unique(all_dat$n)[i])
  result_resp = opt_par_extractor(subset_dat, "Resp1", "Resp2", n = unique(all_dat$n)[i])
  result_HR = opt_par_extractor(subset_dat, "HR1", "HR2", n = unique(all_dat$n)[i])
  result_Resp = plyr::rename(result_resp, c("radius"="radius_Resp", "emddim"="emddim_Resp", 
                                            "delay"="delay_Resp"))
  result_HR = plyr::rename(result_HR, c("radius"="radius_HR", "emddim"="emddim_HR", "delay"="delay_HR"))
  if (i == 1){
    opt_par_df = cbind(result_Resp, result_HR) 
  } else {
    opt_par_df = rbind(opt_par_df, cbind(result_Resp, result_HR))
  }
}

# Creating dataframe with optimal parameters
opt_df = subset(opt_par_df, select=-c(n))
opt_df = subset(opt_df, select=-c(n))
opt_df = opt_df %>% summarise_all(funs(median(., na.rm = TRUE))) 

rqa_extractor = function(dataset = NULL, t1, t2, embed = embed, delay = delay, radius = radius,  n = NA){ 
  if (is.null(dataset) == F){ 
    t1 = dplyr::select(dataset, t1)
    t2 = dplyr::select(dataset, t2)
  }
  result = try(crqa(t1, t2, embed = embed, delay = delay, radius = radius, normalize = 0,  rescale = 0,  mindiagline = 2,  minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE))
  if (length(result) > 1){
    results_df = data.frame(RR = result[1], DET = result[2], NRLINE = result[3], 
               maxL = result[4], L = result[5], ENTR = result[6],
               rENTR = result[7], LAM = result[8], TT = result[9], n = n)

  } else {
    results_df = data.frame(RR = NA, DET = NA, NRLINE = NA, 
               maxL = NA, L = NA, ENTR = NA,
               rENTR = NA, LAM = NA, TT = NA, n = n)    
  }
  return(results_df)
}

# Removing all selfpaced conditions
all_dat = subset(all_dat, condition != "SelfPaced")


# Natural pairs
for (i in 1:length(unique(all_dat$n))){
  subset_dat = subset(all_dat, n == unique(all_dat$n)[i])
  result_Resp = rqa_extractor(subset_dat, "Resp1", "Resp2", embed = opt_df$emddim_Resp, 
                              delay = opt_df$delay_Resp, radius = opt_df$radius_Resp, n = unique(all_dat$n)[i])
  result_HR = rqa_extractor(subset_dat, "HR1", "HR2", embed = opt_df$emddim_HR, 
                                delay = opt_df$delay_HR, radius = opt_df$radius_HR, n = unique(all_dat$n)[i])
  colnames(result_Resp) = paste("Resp", colnames(result_Resp), sep = "_")
  colnames(result_HR) = paste("HR", colnames(result_HR), sep = "_")
  temp = cbind(result_Resp, result_HR)
  temp$condition = unique(subset_dat$condition)
  temp$group = unique(subset_dat$group)
  if (i == 1){
    realPair_rqa = temp
  } else {
    realPair_rqa = rbind(realPair_rqa, temp)
  }
}

```

2) Do you observe interpersonal coordination in heart rate and respiration? Describe your control baseline, the method used to quantify coordination, and the statistical models used to infer whether coordination was higher than in the baseline. Report the results of the models.

```{r}

all_dat$group = as.factor(all_dat$group)

i = 1 
for (g in seq(unique(all_dat$group))){  
  g1 = unique(all_dat$group)[g]
  non_g1 = unique(all_dat$group)[unique(all_dat$group)!= g1] 
  g2 = sample(non_g1)[1] 
  print(g1)
  for (c in unique(all_dat$condition)){ 
    temp1 = subset(all_dat, group == g1 & condition == c) 
    temp2 = subset(all_dat, group == g2 & condition == c) 
    
      # Running the rqa
    result_Resp = rqa_extractor(t1 = temp1$Resp1, t2 = temp2$Resp2, embed = opt_df$emddim_Resp, 
                                delay = opt_df$delay_Resp, radius = opt_df$radius_Resp)
    result_HR = rqa_extractor(t1 = temp1$HR1, t2 = temp2$HR2, embed = opt_df$emddim_HR, 
                                delay = opt_df$delay_HR, radius = opt_df$radius_HR)
    colnames(result_Resp) = paste("Resp", colnames(result_Resp), sep = "_")
    colnames(result_HR) = paste("HR", colnames(result_HR), sep = "_")
    temp = cbind(result_Resp, result_HR)
    temp$condition = c
    temp$group1 = g1
    temp$group2 = g2
    if (i == 1){ 
      surPair_rqa = temp
      i = 2 
    } else { 
      surPair_rqa = rbind(surPair_rqa, temp)
    }
  print(c)
  }
}

# Creating a loop for shuffled pairs
for (i in 1:length(unique(all_dat$n))){
  subset_dat = subset(all_dat, n == unique(all_dat$n)[i])
  shuffled_dat = as.data.frame(dplyr::select(subset_dat, Resp1, Resp2, HR1, HR2) %>%  sapply(., function(x) sample(x)))
  
    # Running the rqa
  result_Resp = rqa_extractor(shuffled_dat, t1 = "Resp1", t2 = "Resp2", embed = opt_df$emddim_Resp, 
                              delay = opt_df$delay_Resp, radius = opt_df$radius_Resp, n = unique(all_dat$n)[i])
  result_HR = rqa_extractor(shuffled_dat, "HR1", "HR2", embed = opt_df$emddim_HR, 
                                delay = opt_df$delay_HR, radius = opt_df$radius_HR, n = unique(all_dat$n)[i])
  colnames(result_Resp) = paste("Resp", colnames(result_Resp), sep = "_")
  colnames(result_HR) = paste("HR", colnames(result_HR), sep = "_")
  temp = cbind(result_Resp, result_HR)
  temp$condition = unique(subset_dat$condition)
  temp$group = unique(subset_dat$group)
  if (i == 1){
    shuffledPair_rqa = temp
  } else {
    shuffledPair_rqa = rbind(shuffledPair_rqa, temp)
  }
}

shuffledPair_rqa$pairing = "shuffledPair"
surPair_rqa1 = select(surPair_rqa, -c(group1, group2))
surPair_rqa1$pairing = "surPair"
surPair_rqa1$group = surPair_rqa$group1
realPair_rqa$pairing = "realPair"
rqa_df = rbind(shuffledPair_rqa, surPair_rqa1, realPair_rqa)

# Heartrate (HR)

# RR for HR
mdl1.1 = lmer(HR_RR ~ pairing+condition + (1 | group), rqa_df, REML = F)
summary(mdl1.1)
#L for HR
mdl1.2 = lmer(HR_L ~ pairing+condition + (1 | group), rqa_df, REML = F)
summary(mdl1.2)
#TT for HR
mdl1.3 = lmer(HR_TT ~ pairing+condition + (1 | group), rqa_df, REML = F)
summary(mdl1.3)

# Respiration (Resp)

# RR for Resp
mdl1.2 = lmer(Resp_RR ~ pairing+condition + (1 | group), rqa_df, REML = F)
summary(mdl1.2)
# L for Resp 
mdl2.2 = lmer(Resp_L ~ pairing+condition + (1 | group), rqa_df, REML = F)
summary(mdl2.2)
# TT for Resp
mdl2.3 = lmer(Resp_TT ~ pairing+condition + (1 | group), rqa_df, REML = F)
summary(mdl2.3)

```

3) Do you observe differences in coordination between conditions? Report the models and results.

```{r}

# Heartrate (HR)

# RR for HR:
mdl1.4 = lmer(HR_RR ~ condition + (1 | group), realPair_rqa, REML = F)
summary(mdl1.4)
# L for HR: 
mdl1.5 = lmer(HR_L ~ condition + (1 | group), realPair_rqa, REML = F)
summary(mdl1.5)
# TT for HR: 
mdl1.6 = lmer(HR_TT ~ condition + (1 | group), realPair_rqa, REML = F)
summary(mdl1.6)

# Respiration (Resp)

# RR for Resp: 
mdl1.4 = lmer(Resp_RR ~ condition + (1 | group), realPair_rqa, REML = F)
summary(mdl1.4)
# L for Resp: 
mdl2.5 = lmer(Resp_L ~ condition + (1 | group), realPair_rqa, REML = F)
summary(mdl2.5)
# TT for Resp: 
mdl2.6 = lmer(Resp_TT ~ condition + (1 | group), realPair_rqa, REML = F)
summary(mdl2.6)

```

4) Is respiration coordination a likely driver of heart rate coordination? Describe how you would test for it. Bonus points if you actually run the tests and report methods and results.

N.B. to give you a bit more data I included data from last year (Study1) and from your class (Study2). Note that synchronouns and turn-taking are the same across both studies, but the third condition is different: last year it was self-paced joint reading; this year it was the tv-series conversation. So you might want to exclude the self-paced reading (but, up to you!)

## Step by step suggestions to solve the assignment

### Exploring physiological signals

- Choose one pair (one pair, three conditions)
- Load the logs
- Produce a plot of the participants' respiration signal and a different one of the participants' HR signal (for inspecting whether the data is usable)
  N.B: remember the slides: artifacts, downsampling, scaling.
  N.B. The gridExtra::grid.arrange() function allows you to display the plots side by side. E.g. grid.arrange(plot1, plot2, plot3, ncol=3)
- Can you eye-ball which condition if any displays more physiological coordination?

- Run crqa on heart rate and respiration data (find parameters, run crqa)
- Does this tell you more than just eyeballing the plots?

### Systematically pre-process the data
- Loop through all the files (either with a loop or with a function), check which files should be excluded, if any, and save the pre-processed time-series. Tip: plot and visually inspect the data to figure out which should be excluded.
- Run crqa on all the pre-processed time-series and save the output (don't forget to add columns with study, group, condition and trial). Tip: remember to first assess optimal parameters (dimensions, delay, radius) across all timeseries. Tip: it will often fail, just take whatever parameters you get, select optimal across timeseries parameters and run crqa on all timeseries with those. Tip: double check the rr. When I ran the loop, I got very low rr, so I adjusted the radius until the average of rr across all pairs was approx. 4%.

### Creating controls: shuffled controls
 - loop through all pairs and conditions
 - shuffle the timeseries (take a timeseries and rearrange its values in a random order). Tip check the sample() function
 - run crqa and save the output. NB. which delay, embed, radius parameters should you use?
 - statistically compare the crqa indexes in real and shuffled pairs
 
### TRICKY! Creating controls: surrogate pair controls
 - Per each real pair, identify at least one surrogate pair (matching one of the participants, with somebody doing the same task, but in a different pair). Tip: Celine will share a commented script
 - Run crqa on all the surrogate pairs and save the output. NB. which delay, embed, radius parameters should you use?
 - Test whether crqa shows a difference between real and surrogate pairs

### Testing effects of conditions
 - make a (probably underpowered) mixed model testing effects of the different conditions on heart rate and respiration coordination
 - N.B: would it make sense to include surrogate pairs? and if so how? what would that tell you?

### Effects of respiration coordination on heart rate coordination
 - describe how you would test those.
 - Optional: run the models and report them




